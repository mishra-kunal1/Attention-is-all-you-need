# Training of Transformer architecture on a Free GPU for English to German Translation

This project involves training a Transformer model on Colab GPU to translate English sentences into German. The model is trained on a dataset containing 15,000 pairs of English and German sentences.
Dataset link - [Download Dataset](https://drive.google.com/file/d/1sD3WFeY_0ulkiskkJFuuvDkDdxFWsAu1/view?usp=drive_link)

![colabvideo](https://github.com/mishra-kunal1/Attention-is-all-you-need/assets/99056351/596cb75d-44ec-4255-aef3-651f7420a8f7)


### TODO
- Model is overfitting, need to reduce the test error as well.
- Add inference to predict english to german sentence.
- Experiment with pretrained tokenizers such as SentencePiece and TikToken.
- Train the model on parallel GPUs

For beter understanding you can refer to the blogs 
Blog Link - [Intro blog](https://medium.com/@kunalmishra78/attention-is-all-you-need-paper-implementation-from-scratch-on-colab-7679289d1022) 



